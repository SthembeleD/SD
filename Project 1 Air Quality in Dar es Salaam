#in this project i will:
#Get data from a MongoDB database
#Explore and clean time series data.
#Build autoregression models.
#Tune hyperparameters.


#Importing Libraries 
import inspect
import time
from pprint import PrettyPrinter
import matplotlib.pyplot as plt
import pandas as pd
import plotly.express as px
import seaborn as sns
from pymongo import MongoClient
import pytz
from statsmodels.tsa.ar_model import AutoReg
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.arima.model import ARIMA

#Preparing Data connecting to MongoDB server and assigning collection for Dar es Salaam
client = MongoClient(host="localhost", port=27017)
db = client["air-quality"]
dar = db["dar-es-salaam"]

for collection in db.list_collections():
    print(collection['name'])
#OUTPUT
lagos
system.buckets.lagos
system.views
dar-es-salaam
system.buckets.dar-es-salaam
nairobi
system.buckets.nairobi


# Creating a Wrangle function to extract all sites with most total readings
# The function will Remove all outliers readings that are above 100 
# ||Resample Data, impute missing values and return series y
def wrangle(collection):
    results = collection.find(
        {"metadata.site": 11, "metadata.measurement": "P2"},
        projection={"P2": 1, "timestamp": 1, "_id": 0},   # ---> focus/ limit to only "P2" and timestamp
    )
df = pd.DataFrame(results).set_index("timestamp")
    # Localize time
    df.index = df.index.tz_localize("UTC").tz_convert("Africa/Dar_es_Salaam")
    
    # Remove outliers
    df = df[df["P2"] < 100]
    
    # Resample to 1hour period, fill in missing values
    y = df["P2"].resample("1H").mean().fillna(method='ffill')
    return y
 #OUTPUT
timestamp
2018-01-01 03:00:00+03:00    9.456327
2018-01-01 04:00:00+03:00    9.400833
2018-01-01 05:00:00+03:00    9.331458
2018-01-01 06:00:00+03:00    9.528776
2018-01-01 07:00:00+03:00    8.861250
Freq: H, Name: P2, dtype: float64


# Create a time series plot of the readings in y
fig, ax = plt.subplots(figsize=(15, 6))
y.plot( #used y instead of y["P2"] since our y is a pd Series
xlabel="Date",
ylabel="PM2.5 Level",
title="Dar es Salaam PM2.5 Levels",
)

# Ploting rolling average of readings in y
fig, ax = plt.subplots(figsize=(15, 6))
fig, ax = plt.subplots(figsize=(15, 6))
y.rolling(168).mean().plot(ax=ax)
plt.xlabel="Date"
plt.ylabel="PM2.5 Level"
plt.title="Dar es Salaam PM2.5 Levels",

# Creating an ACF plot for the data in y
fig, ax = plt.subplots(figsize=(15, 6))
fig, ax = plt.subplots(figsize=(15, 6))
plot_acf(y, ax=ax)
plt.xlabel= "Lag [hours]"
plt.ylabel = "Correlation Coefficient"
plt.title = "Dar es Salaam PM2.5 Readings, ACF"

#SPLIT y INTO TRAINIG AND TEST SETS, 90% OF THE DATA BEING TRAINING DATA WHILE 10% BEING TEST DATA
cutoff_test = int(len(y)*.9)
y_train = y[:cutoff_test]
y_test = y[cutoff_test:]
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)
#OUTPUT
y_train shape: (1944,)
y_test shape: (216,

#BUILDING A MODEL 
#CALCULATING BASELINE MEAN ABSOLUTE ERROR FOR MODEL
y_train_mean = y_train.mean()
y_pred_baseline = [y_train_mean] * len(y_train)
mae_baseline = mean_absolute_error(y_train, y_pred_baseline)
print("Mean P2 Reading:", y_train_mean)
print("Baseline MAE:", mae_baseline)
#OUTPUT
Mean P2 Reading: 8.57142319061077
Baseline MAE: 4.053101181299159


# USING AUTOReg MODEL TO PREDICT PM2.5 READINGS USING FOR LOOP TO TRAIN AR MODEL
# EACH TIME A MODEL IS TRAINED , MEAN ABSOLUTE ERROR WILL ALSO BE CALCULATED
from statsmodels.tsa.ar_model import AutoReg
from sklearn.metrics import mean_absolute_error

p_params = range(1, 31)
maes = []
for p in p_params:
    #Train model
    model = AutoReg(y_train, lags=p).fit()
    
    #Generate in-sample pred
    y_pred = model.predict().dropna()
        
    #Calculate mae
    mae = mean_absolute_error(y_train.iloc[p:], y_pred)
    maes.append(mae)
    mae_series = pd.Series(maes, name="mae", index=p_params)
mae_series.head()
#OUTPUT
1    1.059376
2    1.045182
3    1.032489
4    1.032147
5    1.031022
Name: mae, dtype: float64

#  Calculate the training residuals for best_model and assign the result to y_train_resid
y_pred = best_model.predict().dropna()
y_train_resid = best_model.resid
y_train_resid.name = "residuals"
y_train_resid.head()
y_train_resid = y_train.loc[y_pred.index] - y_pred
y_train_resid.name = "residuals"

# Creatngi a histogram of y_train_resid
y_train_resid.hist()
plt.xlabel = "Residuals"
plt.ylabel = "Frequency"
plt.title = "Best Model, Training Residuals"

# Performing walk-forward validation for your model for the entire test set y_test
y_pred_wfv = pd.Series()
history = y_train.copy()
for i in range(len(y_test)):
    model = AutoReg(history, lags=best_p).fit()
    next_pred = model.forecast()      # next value after end of history
    y_pred_wfv = y_pred_wfv.append(next_pred)
    history = history.append(y_test[next_pred.index])
    
y_pred_wfv.name = "prediction"
y_pred_wfv.index.name = "timestamp"
y_pred_wfv.head()
#OUTPUT
timestamp
2018-03-23 03:00:00+03:00    10.383307
2018-03-23 04:00:00+03:00     8.268941
2018-03-23 05:00:00+03:00    15.172779
2018-03-23 06:00:00+03:00    33.480666
2018-03-23 07:00:00+03:00    39.576329
Freq: H, Name: prediction, dtype: float64

# Communicating results
#Put the values for y_test and y_pred_wfv into the DataFrame df_pred_test

import plotly.express as px
import pandas as pd

# Put test and walk-forward validation values
# in a dataframe and plot df
df_pred_test = pd.DataFrame(
    {"y_test": y_test, "y_pred_wfv": y_pred_wfv}
)
fig = px.line(df_pred_test, labels={"value": "PM2.5"})
fig.update_layout(
    title="Dar es Salaam, WFV Predictions",
    xaxis_title="Date",
    yaxis_title="PM2.5 Level",
)
